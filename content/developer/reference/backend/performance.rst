:custom-css: performance.css

===========
Performance
===========

How to make a piece of code run as fast as possible? This page will hopefully give tips and tools to
achieve this goal.

.. _performance/profiling:

Profiling
=========

The first step when trying to optimize some flow is to understand where the code spends time.

Odoo provides integrated profiling tools, allowing to save all executed queries and/or stack_traces
during execution.

Profiling tools can either be used to profile all requests made to the server for a specific user
session, or be used manually by a developer to profile some part of the code.

In both cases, different collectors are available. A :ref:`collector
<performance/profiling/collectors>` is specialized to collect some piece of information in a
standard format (SQL, traces...) and, for some of them, a custom :ref:`execution context
<performance/profiling/execution_context>` can be added by the developers to create virtual levels
of stack and add extra information.

Even if the profiling tools are designed to be as light as possible, they can still impact
performance, which means that results must me interpreted wisely.

Results can be either analyzed with custom tools (saved in a JSON file or in the database), or
inspected with the integrated SpeedScope view.

.. image:: performance/flamegraph_example.png
   :align: center

.. _performance/profiling/user_interface:

Profiling from the user interface
---------------------------------

This is the easiest way to profile in Odoo but it focuses only on web flows since only requests can
be profiled this way.

The first thing to know is that enabling profiling on a request may impact server load since each
request will have extra work processing the profiler result and profiling results uses some storage.
This is why this option must be enabled in the database settings for a certain period of time. When
enabled on the database, all users can enable the profiler for their own session. Profiling stays
active on the session until explicitly disabled, or if the limit set in the database settings is
reached. Odoo Online (SaaS) instances cannot be profiled.

When logged as admin, trying to enable profiling on the session will show a wizard to help user
enabling profiling. This can also be done manually going in the settings in debug mode.

.. image:: performance/enable_profiling_wizard.png
   :align: center

For production databases, it is advised to choose the shorter period possible. Once it is done, any
use is able to enable profiling for their session.

Open the debug menu again and enable the profiling again. Three :ref:`collectors
<performance/profiling/collectors>` are available:

- `sql`
- `traces`
- `qweb`

The SyncCollector is not available on purpose. By default, The :ref:`SqlCollector
<performance/profiling/collectors/sql>` and :ref:`PeriodicCollector
<performance/profiling/collectors/periodic>` are enabled. Beside the collectors, two options are
available:

- Interval: Used by the periodic collector to define intervals between two samples.
- Add qweb directive context: Adds execution context when entering/exiting qweb directive. Useful
  for the `sql` and `traces` collectors, but adds an overhead to directives.

.. image:: performance/profiling_debug_menu.png
   :align: center

Disabling the `sql` collector will give results closer to an execution without profiling but the
executed queries wont be available. Keeping the two collectors is a good compromise but keep this in
mind while analyzing the results.

Once enabled, all requests to the server will be profiled and saved into an ir.profile entry,
grouped into the current profile session. Once finished, disable the profiling and access the result
using the top tight icon.

.. image:: performance/profiling_web.png
   :align: center

In this example we profiled the /web page will all related resources. From this list, you can access
the speedscope results. `Speedscope <https://github.com/jlfwong/speedscope>`_ is an open source app
allowing to visualize a flamegraph. Speedscope usage is outside of the scope of this tutorial, but
be aware that a lot of tools are available: search, highlight of similar frames, zoom on frame,
timeline, left heavy, sandwich view...

Regarding the results generated by odoo, we can note that the top menu offers different view modes
depending on what was profiled. By default with both `sql` and `traces`:

.. image:: performance/speedscope_modes.png
   :align: center

- The combined view shows SQL queries and traces merged togethers.
- The combined no context shows the same result but ignores saved execution_context.
- The SQL (no gap) view represents all SQL queries as if they were executed after each other,
  without any Python logic. This is useful for optimizing SQL only.
- The SQL (density) view represent SQL queries only, leaving gap between them. This can be useful to
  spot if eiter SQL or Python is the problem, and to identify zones in where many small queries
  could be batched.
- The frames view displays the results of the Periodic collector only.

.. _performance/profiling/python:

Profiling from Python code
--------------------------

Using the profiler manually can be convenient to profile a specific method or a part of the code.
It can be a test, a compute method, or the entire loading. The profiler is a context manager that
takes parameters to define what you want to record:

.. automodule:: odoo.tools.profiler
   :members: Profiler

Without any parameter, the Profiler enables the `sql`, `traces`, and `save` profiles on the
database, just like when enabling them from the interface.

It is possible to configure the profiler with the `collectors` parameter: a list of string and/or
:ref:`collector <performance/profiling/collectors>` objects.

.. code-block:: python

   with Profiler(collectors=['sql', PeriodicCollector(interval=0.1)]):
       ...

   with Profiler(collectors=['qweb']):
       ...

The db parameter is mainly useful in low level contexts where the database cannot be detected
automatically on the thread, or to disable the automatic creation of an ir.profiler record with
`db=None`.

The profiler can automatically disable gc when used programmatically. This can be useful for long
executions during which gc activation may be randomly triggered, especially during external calls
like those to `postgresql`, thus showing unexpectedly slow calls.

Profiling tests
~~~~~~~~~~~~~~~

A profiler shortcut is available for test classes. All executions of a test_method will be grouped
under the same session, and the profile will be named with regard to the test state. This is
especially useful when using the `@warmup` en `@users` decorators.

.. code-block:: python

   with self.profiler():
       with self.assertQueryCount(__system__=1211):
           ...

Note that, in this example, the profiler is outside of the assertQueryCount in order to catch
queries made when exiting the context manager (flush...).

.. _performance/profiling/pitfalls:

Performance pitfalls
--------------------

- Be careful about *randomness*. Multiple executions may lead to different results. E.g., A garbage
  collector being triggered during execution.
- Be careful with blocking calls. In some cases, external c_call may take some time before releasing
  the GIL, thus leading to unexpected long frames with the PeriodicCollector. This should be
  detected by the profiler and give a warning. It is possible to trigger the profiler manually
  before such calls if needed.
- Pay attention to the cache. Profiling before that the view/assets/... are in cache can lead to
  different results.
- Be aware of profiler overhead. The `sql` profiler's overhead can be important when a lot of small
  queries are executed. Profiling is practical to spot a problem but you may want to disable the
  profiler in order to measure the real impact of a code change.
- Profiling results can be memory intensive. In some cases (e.g., profiling an install or a long
  request), it is possible that you reach memory limit, especially when rendering the speedscope
  results which can lead to an HTTP 500 error. In this case, you may need to start the server with
  a higher memory limit: `--limit-memory-hard $((8*1024**3))`.

.. _performance/profiling/collectors:

Collectors
----------

There are currently 4 main collectors available (3 of them being available from the interface): the
:ref:`SqlCollector <performance/profiling/collectors/sql>`, the :ref:`PeriodicCollector
<performance/profiling/collectors/periodic>`, the :ref:`SyncCollector
<performance/profiling/collectors/sync>`, and the :ref:`QwebCollector
<performance/profiling/collectors/qweb>`.

.. _performance/profiling/collectors/sql:

SQL Collector
~~~~~~~~~~~~~

TODO: key=`sql`, class=`SqlCollector`

The SQL collector saves all SQL queries made to the database in the current thread (for all cursors)
as well as the stack trace. This is especially useful to debug query counts, or add information to
the :ref:`PeriodicCollector <performance/profiling/collectors/periodic>` in the combined SpeedScope
view. The overhead of the collector is added for each query to the analysed thread, meaning that
using this collector on a lot of small queries may impact execution time and other profilers.

.. _performance/profiling/collectors/periodic:

Periodic Collector
~~~~~~~~~~~~~~~~~~

TODO: key=`traces_async`, class=`PeriodicCollector`

This Collector runs in a separate thread and saves the stack trace of the analysed thread at every
interval. This is one of the best way to analyse performances, as it should have a very low impact
on the execution. The frequency (defined by the interval parameter) must be chosen wisely. Too low
and you may lose information, too high and you may have memory issues with long requests. The
default interval is 10 ms.

.. _performance/profiling/collectors/sync:

Sync Collector
~~~~~~~~~~~~~~

TODO: key=`traces_sync`, class=`SyncCollector`

This collector saves the stack for every function call and return. It is useless for performances
analysis since the overhead of using it is high, but it can be useful to understand complex flows
and follow the execution of some code, mainly for debugging.

.. _performance/profiling/collectors/qweb:

QWeb Collector
~~~~~~~~~~~~~~

TODO: key=`qweb`, class=`QwebCollector`

This collector is mainly useful for optimizing views. It saves the Python execution time and queries
of all directive. As for the SQL collector, the overhead can be important when executing a lot of
small directives. Qweb collector's results are a little different from other collectors in term of
collected data, and can be analysed from the `ir.profile` view form using a custom widget.

It is also possible to create custom collectors as far as they respect the current collector API.

.. _performance/profiling/execution_context:

Execution context
-----------------

Stack traces can be useful to understand where the program was at some point when no information
about the state of the memory is available. This can be problematic when profiling code inside
loops where everything seems to be part of the same block of execution, even if only one iteration
is slower than the others. When displayed with speedscope, the execution context appears as
additional levels in the stack.

Execution contexts are dictionaries mapped to some level of the stack saved on the thread. This
allows to provide information to collectors. An helper context manager is available for that:

.. code-block:: python

   for index, package in enumerate(graph, 1):
       with ExecutionContext(module_name = package.name):
           module_name = package.name

This example adds the name of the currently installed/loaded module in the execution context.

TODO XDO explain how can be used in loading.py

.. _performance/good_practices:

Good practices
==============

.. _performance/good_practices/batch:

Batch operations
----------------

When working with recordsets, it is almost always better to batch operations.

A typical mistake is to execute SQL in a loop, in a search for example.

.. rst-class:: bad-example
.. code-block:: python

   def _compute_count(self):
       for record in self:
           domain = [('related_id', '=', record.id)]
           record.count = other_model.search_count(domain)

This performs an SQL query for each record. In this kind of example, we can replace the
`search_count` with a `read_group`.

.. rst-class:: good-example
.. code-block:: python

   def _compute_count(self):
       if self.ids:
           domain = [('related_id', 'in', self.ids)]
           counts_data = other_model.read_group(domain, ['related_id'], ['related_id'])
           mapped_data = {
               count['related_id'][0]: count['related_id_count'] for count in counts_data
           }
       else:
           mapped_data = {}
       for record in self:
           record.count = mapped_data.get(record.id, 0)

Grouping SQL queries removes the added cost of reading the database and helps PostgreSQL to optimise
the query plan when possible.

.. important::
   This example is not optimal/correct in all cases. It is only a substitute for a `search_count`.
   Another solution could be to prefetch and count the inverse `One2many` field.

Another example is the record creation. The framework offers the possibility to create records in
batch. This has no impact in most cases, but creating records in batch and keeping `create`
overrides compatible with the `api.model_create_multi` decorator helps the framework to optimize
fields computation, and give the opportunity to optimise `create` overrides in some cases.

.. code-block:: python

   create_values = []
   for name in ['foo', 'bar']:
       create_values.append({'name': name})
   records = model.create(create_values)

Another frequent mistake is to miss the possible batch prefetching when reading on a single browsed
record inside a loop.

.. rst-class:: bad-example
.. code-block:: python

   for record_id in record_ids:
       model.browse(record_id)
       record.foo  # this will trigger one query per record_id

.. rst-class:: good-example
.. code-block:: python

   records = model.browse(record_ids)
   for record in records:
       record.foo  # this will trigger one query for all record_ids

In this last example, the `prefetch_ids` of the recordset shows that each `record_id` is part of
`record_ids`, and thus they will be managed togethers. When reading the first record, the framework
prefetches all records at once. In the rare case where browsing all records together is unpractical,
the `with_prefetch` method can help achieve the same goal.

.. code-block:: python

   for values in values_list:
       message = self.browse(values['id']).with_prefetch(self.ids)

.. _performance/good_practices/algorithmic_complexity:

Algorithmic complexity
----------------------

Algorithmic complexity is a measure of how long an algorithm would take to complete given an input
of size n

In some cases the straightforward algorithm implies two nested loops. It can be justified in some
cases, but it should be well thought. In some cases, it can be avoided by preparing data the right
way.

.. rst-class:: bad-example
.. code-block:: python

   for record in self:
       for result in results:
           if results['id'] == record.id:
               record.foo = results['foo']
               break
       else:
           record.foo = 0  # default value

This simple example is O(n²) and can be optimized by preparing data in a dict.

Assuming that all result have a different id:

.. rst-class:: good-example
.. code-block:: python

   mapped_result = {result['id']: result for result in results}
   for record in self:
       record.foo = results.get(record.id)['foo']

This kind of change is not always as obvious as this one. It sometimes needs some thought.

Correct usage of data structures is important too. In the last example, using a dict allows
accessing an element in O(1), but sometimes quadratic complexity can be hidden.

.. rst-class:: bad-example
.. code-block:: python

   invalid_ids = self.search(domain).ids
   for record in self:
       if record.id in invalid_ids:
           ...

If invalid_ids is a list like the result of a search, the complexity may be quadratic. In this cases
we will prefer set operations, like casting `invalid_ids` in a set.

Depending on your input, you can either cast the list into a set outside of the loop, or prefer
recordset operations.

.. rst-class:: good-example
.. code-block:: python

   invalid_ids = self.search(domain)
   for record in self - invalid_ids:
       ...

or

.. rst-class:: good-example
.. code-block:: python

   invalid_ids = set(invalid_ids)
   for record in self:
       if record.id in invalid_ids:
           ...

.. _performance/good_practices/index:

Use indexes
-----------

If your code performs a search on some criteria, or if the user needs to search on a field, it may
be a good idea to index the column.

.. code-block:: python

   name = fields.Char(string="Name", index=True)

Be careful to not index everything, index consume space and have performances drawback on `INSERT`,
`UPDATE` and `DELETE`.

.. _reference/performance/populate:

Database population
===================

Odoo CLI offers a :ref:`database population <reference/cmdline/populate>` feature.

.. code-block:: console

   odoo-bin populate

Instead of the tedious manual, or programmatic, specification of test data, one can use this feature
to fill a database on demand with the desired number of test data. This can be used to detect
diverse bugs or performance issues in tested flows.

.. _reference/performance/populate/methods:

To specify this feature for a given model, the following methods and attributes can be defined.

.. currentmodule:: odoo.models

.. autoattribute:: Model._populate_sizes
.. autoattribute:: Model._populate_dependencies
.. automethod:: Model._populate
.. automethod:: Model._populate_factories

.. note::
   You have to define at least :meth:`~odoo.models.Model._populate` or
   :meth:`~odoo.models.Model._populate_factories` on the model to enable database population.

Example model
-------------

.. code-block:: python

    from odoo.tools import populate

    class CustomModel(models.Model)
        _inherit = "custom.some_model"
        _populate_sizes = {"small": 100, "medium": 2000, "large": 10000}
        _populate_dependencies = ["custom.some_other_model"]

        def _populate_factories(self):
            # Record ids of previously populated models are accessible in the registry
            some_other_ids = self.env.registry.populated_models["custom.some_other_model"]

            def get_some_field(values=None, random=None, **kwargs):
                """ Choose a value for some_field depending on other fields values.

                :param dict values:
                :param random: seeded :class:`random.Random` object
                """
                field_1 = values['field_1']
                if field_1 in [value2, value3]:
                    return random.choice(some_field_values)
                return False

            return [
                ("field_1", populate.randomize([value1, value2, value3])),
                ("field_2", populate.randomize([value_a, value_b], [0.5, 0.5])),
                ("some_other_id", populate.randomize(some_other_ids)),
                ("some_field", populate.compute(get_some_field, seed="some_field")),
                ('active', populate.cartesian([True, False])),
            ]

        def _populate(self, size):
            records = super()._populate(size)

            # If you want to update the generated records
            # E.g setting the parent-child relationships
            records.do_something()

            return records

Population tools
----------------

Multiple population tools are available to easily create the needed data generators.

.. automodule:: odoo.tools.populate
   :members: cartesian, compute, constant, iterate, randint, randomize
