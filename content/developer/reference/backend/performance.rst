:custom-css: performance.css

===========
Performance
===========

How to make a piece of code run as fast as possible? This page will hopefully give tips and tools to
achieve this goal.

.. _performance/profiling:

Profiling
=========

The first step when trying to optimize some flow is to understand where the code spends time.

Odoo provides integrated profiling tools, allowing to save all executed queries and/or stack_traces
during execution.

Profiling tools can either be used to profile all requests made to the server for a specific user
session, or be used manually by a developer to profile some part of the code.

In both cases, different collectors are available. A :ref:`collector
<performance/profiling/collectors>` is specialized to collect some piece of information in a
standard format (SQL, traces...) and, for some of them, a custom :ref:`execution context
<performance/profiling/execution_context>` can be added by the developers to create virtual levels
of stack and add extra information.

Even if the profiling tools are designed to be as light as possible, they can still impact
performance, which means that results must me interpreted wisely.

Results can be either analyzed with custom tools (saved in a JSON file or in the database), or
inspected with the integrated SpeedScope view.

.. image:: performance/flamegraph_example.png
   :align: center

.. _performance/profiling/user_interface:

Profiling from the user interface
---------------------------------

This is the easiest way to profile in Odoo but it focuses only on web flows since only requests can
be profiled this way.

The first thing to know is that enabling profiling on a request may impact server load since each
request will have extra work processing the profiler result and profiling results uses some storage.
This is why this option must be enabled in the database settings for a certain period of time. When
enabled on the database, all users can enable the profiler for their own session. Profiling stays
active on the session until explicitly disabled, or if the limit set in the database settings is
reached. Odoo Online (SaaS) instances cannot be profiled.

When logged as admin, trying to enable profiling on the session will show a wizard to help user
enabling profiling. This can also be done manually going in the settings in debug mode.

.. image:: performance/enable_profiling_wizard.png
   :align: center

For production databases, it is advised to choose the shorter period possible. Once it is done, any
user is able to enable profiling for their session.

Open the debug menu again and enable the profiling again. Three :ref:`collectors
<performance/profiling/collectors>` are available:

TODO: use complete names

- `sql`
- `traces`
- `qweb`

The SyncCollector is not available on purpose. By default, The :ref:`SqlCollector
<performance/profiling/collectors/sql>` and :ref:`PeriodicCollector
<performance/profiling/collectors/periodic>` are enabled. Beside the collectors, two options are
available:

- Interval: Used by the periodic collector to define intervals between two samples.
- Add qweb directive context: Adds execution context when entering/exiting qweb directive. Useful
  for the `sql` and `traces` collectors, but adds an overhead to directives.

.. image:: performance/profiling_debug_menu.png
   :align: center

Disabling the `sql` collector will give results closer to an execution without profiling but the
executed queries wont be available. Keeping the two collectors is a good compromise but keep this in
mind while analyzing the results.

Once enabled, all requests to the server will be profiled and saved into an `ir.profile` record,
grouped into the current profile session. Once finished, disable the profiling and access the result
using the top tight icon.

.. image:: performance/profiling_web.png
   :align: center

In this example we profiled the `/web` page will all related resources. From this list, you can
access the `speedscope <https://github.com/jlfwong/speedscope>`_ :dfn:`an open source app allowing
to visualize a flamegraph` results.

.. tip::
   Speedscope falls out of the scope of this documentation but there are a lot of tools to try:
   search, highlight of similar frames, zoom on frame, timeline, left heavy, sandwich view...

Regarding the results generated by odoo, we can note that the top menu offers different view modes
depending on what was profiled. By default with both `sql` and `traces`:

.. image:: performance/speedscope_modes.png
   :align: center

- The combined view shows SQL queries and traces merged togethers.
- The combined no context shows the same result but ignores saved execution_context.
- The SQL (no gap) view represents all SQL queries as if they were executed after each other,
  without any Python logic. This is useful for optimizing SQL only.
- The SQL (density) view represent SQL queries only, leaving gap between them. This can be useful to
  spot if eiter SQL or Python is the problem, and to identify zones in where many small queries
  could be batched.
- The frames view displays the results of the Periodic collector only.

.. _performance/profiling/python:

Profiling from Python code
--------------------------

Using the profiler manually can be convenient to profile a specific method or a part of the code.
It can be a test, a compute method, or the entire loading. The profiler is a context manager that
takes parameters to define what to record.

.. automodule:: odoo.tools.profiler
   :members: Profiler

Without any parameter, the Profiler enables the SQL and Periodic collector, and saves the
`ir.profile` records on the database, just like when enabling them from the interface.

It is possible to configure the profiler with the `collectors` parameter: a list of string and/or
:ref:`collector <performance/profiling/collectors>` objects.

.. example::
   .. code-block:: python

      with Profiler(collectors=['sql', PeriodicCollector(interval=0.1)]):
          ...

      with Profiler(collectors=['qweb']):
          ...

The `db` parameter is mainly useful in low level contexts where the database cannot be detected
automatically on the thread, or to disable the automatic creation of an `ir.profile` record with
`db=None`.

The profiler can automatically disable garbage collection when used programmatically. This can be
useful for long executions during which garbage collection activation may be randomly triggered,
especially during external calls like those to `postgresql`, thus showing unexpectedly slow calls.

Profiling tests
~~~~~~~~~~~~~~~

A shortcut is available for profiling test classes: :code:`self.profiler()`.

.. example::
   .. code-block:: python

      with self.profiler():
          with self.assertQueryCount(__system__=1211):
              ...

   .. note::
      The profiler called outside of the `assertQueryCount` in order to catch queries made when
      exiting the context manager (e.g., flush).

All executions of a test method are grouped under the same profiling session, and the `ir.profile`
record is named with regard to the test state. This is especially useful when using the `@warmup`
and `@users` decorators.

.. _performance/profiling/pitfalls:

Performance pitfalls
--------------------

TODO: move further below

- Be careful about *randomness*. Multiple executions may lead to different results. E.g., a garbage
  collector being triggered during execution.
- Be careful with blocking calls. In some cases, external c_call may take some time before releasing
  the GIL, thus leading to unexpected long frames with the PeriodicCollector. This should be
  detected by the profiler and give a warning. It is possible to trigger the profiler manually
  before such calls if needed.
- Pay attention to the cache. Profiling before that the view/assets/... are in cache can lead to
  different results.
- Be aware of profiler overhead. The `sql` profiler's overhead can be important when a lot of small
  queries are executed. Profiling is practical to spot a problem but you may want to disable the
  profiler in order to measure the real impact of a code change.
- Profiling results can be memory intensive. In some cases (e.g., profiling an install or a long
  request), it is possible that you reach memory limit, especially when rendering the speedscope
  results which can lead to an HTTP 500 error. In this case, you may need to start the server with
  a higher memory limit: `--limit-memory-hard $((8*1024**3))`.

.. _performance/profiling/collectors:

Collectors
----------

There are currently 4 collectors available: the :ref:`SQL <performance/profiling/collectors/sql>`,
:ref:`Periodic <performance/profiling/collectors/periodic>`, :ref:`Sync
<performance/profiling/collectors/sync>`, and :ref:`QWeb <performance/profiling/collectors/qweb>`
collectors.

.. _performance/profiling/collectors/sql:

SQL collector
~~~~~~~~~~~~~

TODO: key=`sql`, class=`SqlCollector`

The SQL collector saves all SQL queries made to the database in the current thread (for all cursors)
as well as the stack trace. This is especially useful to debug query counts, or to add information
to the :ref:`performance/profiling/collectors/periodic` in the combined speedscope view. The
overhead of the collector is added for each query to the analysed thread, meaning that using this
collector on a lot of small queries may impact execution time and other profilers.

.. _performance/profiling/collectors/periodic:

Periodic collector
~~~~~~~~~~~~~~~~~~

TODO: key=`traces_async`, class=`PeriodicCollector`

This collector runs in a separate thread and saves the stack trace of the analysed thread at every
interval. This is one of the best way to analyse performances, as it should have a very low impact
on the execution time. The frequency (defined by the `interval` parameter) must be set wisely: too
low and you may lose information, too high and you may have memory issues with long requests. The
default for `interval` is 10 ms.

.. _performance/profiling/collectors/sync:

Sync collector
~~~~~~~~~~~~~~

TODO: key=`traces_sync`, class=`SyncCollector`

This collector saves the stack for every function call and return. It is not recommended for
performance analysis because the overhead is high. It can however be useful to understand complex
flows and follow the execution of some code, mainly for debugging.

.. _performance/profiling/collectors/qweb:

QWeb collector
~~~~~~~~~~~~~~

TODO: key=`qweb`, class=`QwebCollector`

This collector is mainly useful for optimizing views. It saves the Python execution time and queries
of all directive. As for the :ref:`performance/profiling/collectors/sql`, the overhead can be
important when executing a lot of small directives. Qweb collector's results are different from
other collectors in terms of collected data, and can be analysed from the `ir.profile` form view
using a custom widget.

.. _performance/profiling/execution_context:

Execution context
-----------------

Stack traces can be useful to understand where the program was at some point when no information
about the state of the memory is available. This can be problematic when profiling code inside
loops where everything seems to be part of the same block of execution, even if only one iteration
is slower than the others. When displayed with speedscope, the execution context appears as
additional levels in the stack.

TODO XDO screenshot for the execution context

Execution contexts are dictionaries mapped to some level of the stack saved on the thread. This
allows to provide information to collectors. An helper context manager is available for that.

.. example::
   .. code-block:: python

      for index, package in enumerate(graph, 1):
          with ExecutionContext(module_name = package.name):
              module_name = package.name

   This example adds the name of the currently installed/loaded module in the execution context.

   TODO XDO explain how can be used in loading.py

.. _performance/good_practices:

Good practices
==============

.. _performance/good_practices/batch:

Batch operations
----------------

When working with recordsets, it is almost always better to batch operations.

.. example::
   Don't call a method that runs SQL queries while looping over a recordset because it will do so
   for each record of the set.

   .. rst-class:: bad-example
   .. code-block:: python

      def _compute_count(self):
          for record in self:
              domain = [('related_id', '=', record.id)]
              record.count = other_model.search_count(domain)

   Instead, replace the `search_count` with a `read_group` to execute one SQL query for the entire
   batch of records.

   .. rst-class:: good-example
   .. code-block:: python

      def _compute_count(self):
          if self.ids:
              domain = [('related_id', 'in', self.ids)]
              counts_data = other_model.read_group(domain, ['related_id'], ['related_id'])
              mapped_data = {
                  count['related_id'][0]: count['related_id_count'] for count in counts_data
              }
          else:
              mapped_data = {}
          for record in self:
              record.count = mapped_data.get(record.id, 0)

   .. note::
      This example is not optimal nor correct in all cases. It is only a substitute for a
      `search_count`. Another solution could be to prefetch and count the inverse `One2many` field.

.. example::
   Don't create records one after another.

   .. rst-class:: bad-example
   .. code-block:: python

      for name in ['foo', 'bar']:
          model.create({'name': name})

   Instead, accumulate the create values and call the `create` method on the batch. Doing so has
   mostly no impact and helps the framework optimize fields computation.

   .. rst-class:: good-example
   .. code-block:: python

      create_values = []
      for name in ['foo', 'bar']:
          create_values.append({'name': name})
      records = model.create(create_values)

.. example::
   Fail to prefetch the fields of a recordset while browsing a single record inside a loop.

   .. rst-class:: bad-example
   .. code-block:: python

      for record_id in record_ids:
          model.browse(record_id)
          record.foo  # One query is executed per record.

   Instead, browse the entire recordset first.

   .. rst-class:: good-example
   .. code-block:: python

      records = model.browse(record_ids)
      for record in records:
          record.foo  # One query is executed for the entire recordset.

   We can verify that the records are prefetched in batch by reading the field `prefetch_ids` which
   includes each of the record ids.browsing all records together is unpractical,

   If needed, the `with_prefetch` method can be used to disable batch prefetching:

   .. code-block:: python

      for values in values_list:
          message = self.browse(values['id']).with_prefetch(self.ids)

.. _performance/good_practices/algorithmic_complexity:

Reduce the algorithmic complexity
---------------------------------

Algorithmic complexity is a measure of how long an algorithm would take to complete in regard to the
size `n` of the input. When the complexity is high, the execution time can grow quickly as the input
becomes larger. In some cases, the algorithmic complexity can be reduced by preparing the input's
data correctly.

.. example::
   For a given problem, let's consider a naive algorithm crafted with two nested loops for which the
   complexity in in O(n²).

   .. rst-class:: bad-example
   .. code-block:: python

      for record in self:
          for result in results:
              if results['id'] == record.id:
                  record.foo = results['foo']
                  break

   Assuming that all results have a different id, we can prepare the data to reduce the complexity.

   .. rst-class:: good-example
   .. code-block:: python

      mapped_result = {result['id']: result['foo'] for result in results}
      for record in self:
          record.foo = mapped_result.get(record.id)

.. example::
   Choosing the bad data structure to hold the input can lead to quadratic complexity.

   .. rst-class:: bad-example
   .. code-block:: python

      invalid_ids = self.search(domain).ids
      for record in self:
          if record.id in invalid_ids:
              ...

   If `invalid_ids` is a list-like data structure, the complexity of the algorithm may be quadratic.

   Instead, prefer using set operations like casting `invalid_ids` to a set.

   .. rst-class:: good-example
   .. code-block:: python

      invalid_ids = set(invalid_ids)
      for record in self:
          if record.id in invalid_ids:
              ...

   Depending on the input, recordset operations can also be used.

   .. rst-class:: good-example
   .. code-block:: python

      invalid_ids = self.search(domain)
      for record in self - invalid_ids:
          ...

.. _performance/good_practices/index:

Use indexes
-----------

Database indexes can help fasten search operations, be it from a search in the or through the user
interface.

.. code-block:: python

   name = fields.Char(string="Name", index=True)

.. warning::
   Be careful not to index every field as indexes consume space and impact on performance when
   executing one of `INSERT`, `UPDATE`, and `DELETE`.

.. _reference/performance/populate:

Database population
===================

Odoo CLI offers a :ref:`database population <reference/cmdline/populate>` feature through the CLI
command :command:`odoo-bin populate`.

Instead of the tedious manual, or programmatic, specification of test data, one can use this feature
to fill a database on demand with the desired number of test data. This can be used to detect
diverse bugs or performance issues in tested flows.

.. _reference/performance/populate/methods:

To populate a given model, the following methods and attributes can be defined.

.. currentmodule:: odoo.models

.. autoattribute:: Model._populate_sizes
.. autoattribute:: Model._populate_dependencies
.. automethod:: Model._populate
.. automethod:: Model._populate_factories

.. note::
   You have to define at least :meth:`~odoo.models.Model._populate` or
   :meth:`~odoo.models.Model._populate_factories` on the model to enable database population.

.. example::
   .. code-block:: python

       from odoo.tools import populate

       class CustomModel(models.Model)
           _inherit = "custom.some_model"
           _populate_sizes = {"small": 100, "medium": 2000, "large": 10000}
           _populate_dependencies = ["custom.some_other_model"]

           def _populate_factories(self):
               # Record ids of previously populated models are accessible in the registry
               some_other_ids = self.env.registry.populated_models["custom.some_other_model"]

               def get_some_field(values=None, random=None, **kwargs):
                   """ Choose a value for some_field depending on other fields values.

                   :param dict values:
                   :param random: seeded :class:`random.Random` object
                   """
                   field_1 = values['field_1']
                   if field_1 in [value2, value3]:
                       return random.choice(some_field_values)
                   return False

               return [
                   ("field_1", populate.randomize([value1, value2, value3])),
                   ("field_2", populate.randomize([value_a, value_b], [0.5, 0.5])),
                   ("some_other_id", populate.randomize(some_other_ids)),
                   ("some_field", populate.compute(get_some_field, seed="some_field")),
                   ('active', populate.cartesian([True, False])),
               ]

           def _populate(self, size):
               records = super()._populate(size)

               # If you want to update the generated records
               # E.g setting the parent-child relationships
               records.do_something()

               return records

Population tools
----------------

Multiple population tools are available to easily create the needed data generators.

.. automodule:: odoo.tools.populate
   :members: cartesian, compute, constant, iterate, randint, randomize
